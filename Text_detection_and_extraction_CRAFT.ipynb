{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text detection and extraction_CRAFT.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eFE9mXk01JGL",
        "colab_type": "text"
      },
      "source": [
        "# Setting up the environment\n",
        "\n",
        "**Important steps:**\n",
        "\n",
        "1.   Installing required packages\n",
        "2.   Importing required libraries\n",
        "3. Setting up the working directory\n",
        "3. Importing the images and ground truth data\n",
        "4. Cloning CRAFT github repo to use the model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jsKR0KwIqP7P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##Installing required packages\n",
        "!sudo apt install tesseract-ocr\n",
        "! apt install tesseract-ocr\n",
        "! apt install libtesseract-dev\n",
        "! pip install Pillow\n",
        "! pip install pytesseract\n",
        "!pip install jiwer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D4WCqVwBqEnO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# importing required libraries\n",
        "import urllib.request\n",
        "import zipfile\n",
        "import numpy as np\n",
        "import cv2\n",
        "from imutils.object_detection import non_max_suppression\n",
        "import pytesseract\n",
        "from matplotlib import pyplot as plt\n",
        "import pandas as pd\n",
        "import sys\n",
        "import time\n",
        "import matplotlib\n",
        "import matplotlib.pylab as plt\n",
        "import os\n",
        "from os.path import exists, join, basename, splitext\n",
        "from jiwer import wer\n",
        "import re\n",
        "from statistics import mean"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XBmSJ8_zqLUw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Setting up working directory\n",
        "! mkdir -p /content/Text_detection_and_extraction\n",
        "\n",
        "#Using the url to download data\n",
        "url = 'https://s3.amazonaws.com/tech-interview/text_detection.zip'\n",
        "urllib.request.urlretrieve(url, '/content/Text_detection_and_extraction/text_detection.zip')\n",
        "\n",
        "#Extracting the data from zipped folder\n",
        "with zipfile.ZipFile(\"/content/Text_detection_and_extraction/text_detection.zip\", 'r') as zip_ref:\n",
        "  zip_ref.extractall(\"/content/Text_detection_and_extraction\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WSDBUz_RqfMZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Clonining git repo to download CRAFT model\n",
        "\n",
        "git_repo_url = 'https://github.com/clovaai/CRAFT-pytorch.git'\n",
        "project_name = splitext(basename(git_repo_url))[0]\n",
        "if not exists(project_name):\n",
        "  # clone and install\n",
        "  !git clone -q {git_repo_url}\n",
        "  #!cd {project_name} && pip install -q -r requirements.txt\n",
        "\n",
        "sys.path.append(project_name)\n",
        "plt.rcParams[\"axes.grid\"] = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jL7qX3eLqj4v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def download_from_google_drive(file_id, file_name):\n",
        "  # download a file from the Google Drive link\n",
        "  !rm -f ./cookie\n",
        "  !curl -c ./cookie -s -L \"https://drive.google.com/uc?export=download&id={file_id}\" > /dev/null\n",
        "  confirm_text = !awk '/download/ {print $NF}' ./cookie\n",
        "  confirm_text = confirm_text[0]\n",
        "  !curl -Lb ./cookie \"https://drive.google.com/uc?export=download&confirm={confirm_text}&id={file_id}\" -o {file_name}\n",
        "  \n",
        "pretrained_model = 'craft_mlt_25k.pth'\n",
        "if not exists(pretrained_model):\n",
        "  # download the pretrained model\n",
        "  !wget -q -O {pretrained_model} 'https://drive.google.com/uc?authuser=0&id=1Jk4eGD7crsqCCg9C9VjCLkMN3ze8kutZ&export=download'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KZERnlRT2Pi5",
        "colab_type": "text"
      },
      "source": [
        "# Using CRAFT model to predict bounding boxes for the images\n",
        "\n",
        "**Note**: Change the np.array(img) to np.ascontiguousarray(img) at line 43 in the file_utils.py file in the CRAFT-pytorch folder. (This is required for the model to run)\n",
        "\n",
        "**Output:**\n",
        "\n",
        "1. Images with bounding boxes (.jpg files)\n",
        "2. Bounding box coordinates for each image (.txt files)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bibP64EEq0oh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Running the CRAFT model on the images \n",
        "!cd {project_name} && python test.py --trained_model=../{pretrained_model} --test_folder=/content/Text_detection_and_extraction/text_detection/images"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dvNsKM4X2kIU",
        "colab_type": "text"
      },
      "source": [
        "# Using tesseract model to extract text in the images\n",
        "\n",
        "**Process to extract data from one image:**\n",
        "\n",
        "1. Iterate over the bounding boxes for the image\n",
        "2. Crop the image region based on the bbox \n",
        "3. Input the image into the tesseract model to extract text in that region"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IDehhXC9affN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get list of images/files for prediction\n",
        "list_names = os.listdir('/content/Text_detection_and_extraction/text_detection/ground_truth/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7UMZEdSBbKSu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "column_names = [\"x1\",\"y1\",\"x2\",\"y2\",\"x3\",\"y3\",\"x4\",\"y4\"]\n",
        "bbox_text_prediction = pd.DataFrame()\n",
        "\n",
        "for j,name in enumerate(list_names):\n",
        "\n",
        "  name_split = name.split(\"_\")\n",
        "\n",
        "  if len(name_split) == 3:\n",
        "    name = name.split(\"_\")\n",
        "    name_bbox = name[1] + \"_\" + name[2]\n",
        "    name_img = name_bbox.split(\".\")\n",
        "    name_img = name_img[0]+\".jpg\"\n",
        "  else:\n",
        "    name = name.split(\"_\")\n",
        "    name_bbox = name[1]\n",
        "    name_img = name_bbox.split(\".\")\n",
        "    name_img = name_img[0]+\".jpg\"\n",
        "\n",
        "  results_path = \"/content/CRAFT-pytorch/result\"\n",
        "  coordinates = pd.read_csv(join(results_path,\"res_\"+name_bbox),names = column_names)\n",
        "  image = cv2.imread(join('/content/Text_detection_and_extraction/text_detection/images',name_img))\n",
        "\n",
        "  ## Converting the output coordinates from CRAFT model to StartX,StartY,EndX,EndY\n",
        "\n",
        "  coordinates['StartX'] = coordinates[['x1','x2','x3','x4']].min(axis = 1)\n",
        "  coordinates['StartY'] = coordinates[['y1','y2','y3','y4']].min(axis = 1)\n",
        "  coordinates['EndX'] = coordinates[['x1','x2','x3','x4']].max(axis = 1)\n",
        "  coordinates['EndY'] = coordinates[['y1','y2','y3','y4']].max(axis = 1)\n",
        "\n",
        "  boxes = (coordinates[['StartX','StartY','EndX','EndY']])\n",
        "  boxes[boxes < 0] = 0\n",
        "  boxes_list = boxes.values.tolist()\n",
        "  boxes['name'] = name_bbox\n",
        "  boxes[\"text\"] = ' '\n",
        "\n",
        "## Loop to iterate over the bounding boxes -> Crop the image -> Extract the text in the cropped image\n",
        "\n",
        "  for i, (startX,startY,endX,endY) in enumerate(boxes_list):\n",
        "    ## Cropping the image to input to the tesseract model for prediction\n",
        "\n",
        "    r = image[startY:endY, startX:endX]\n",
        "\n",
        "    ## Using the necessary configuration for tesseract model\n",
        "\n",
        "    '''\n",
        "    OCR engine mode - Neural nets LSTM engine\n",
        "    Page segmentation mode - Treat the image as a single word\n",
        "\n",
        "    '''\n",
        "    configuration = (\"--oem 1 --psm 8\")\n",
        "    \n",
        "    ## Using tesseract to predict the text in the cropped image\n",
        "\n",
        "    text = pytesseract.image_to_string(r, config = configuration)\n",
        "    boxes.loc[i,'text'] = text\n",
        "\n",
        "  ### Appedning all the predictions to the dataframe, which can be exported\n",
        "  bbox_text_prediction = bbox_text_prediction.append(boxes,ignore_index = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FoawRles3L7J",
        "colab_type": "text"
      },
      "source": [
        "# Evaluation of the models\n",
        "\n",
        "**Bounding box prediction by CRAFT model:**\n",
        "\n",
        "*   Intersection over union is used as the evaluation metric for bbox predictions\n",
        "*   Based on the threshold for IOU Average precision and recall are calculated as the final metrics\n",
        "\n",
        "**Text extraction by Tesseract:**\n",
        "\n",
        "*   Word error rate (WER) is calculated for the True positive boxes* \n",
        "\n",
        "*Note*: Character error rate is not calculated at the moment\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h2JB8L62Kxlp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### Funtion to calculate Intersection over union of Predicted bbox and ground truth bbox\n",
        "\n",
        "def bb_intersection_over_union(boxA, boxB):\n",
        "\t# determine the (x, y)-coordinates of the intersection rectangle\n",
        "\txA = max(boxA[0], boxB[0])\n",
        "\tyA = max(boxA[1], boxB[1])\n",
        "\txB = min(boxA[2], boxB[2])\n",
        "\tyB = min(boxA[3], boxB[3])\n",
        " \n",
        "\t# compute the area of intersection rectangle\n",
        "\tinterArea = max(0, xB - xA + 1) * max(0, yB - yA + 1)\n",
        " \n",
        "\t# compute the area of both the prediction and ground-truth\n",
        "\t# rectangles\n",
        "\tboxAArea = (boxA[2] - boxA[0] + 1) * (boxA[3] - boxA[1] + 1)\n",
        "\tboxBArea = (boxB[2] - boxB[0] + 1) * (boxB[3] - boxB[1] + 1)\n",
        " \n",
        "\t# compute the intersection over union by taking the intersection\n",
        "\t# area and dividing it by the sum of prediction + ground-truth\n",
        "\t# areas - the interesection area\n",
        "\tiou = interArea / float(boxAArea + boxBArea - interArea)\n",
        " \n",
        "\t# return the intersection over union value\n",
        "\treturn iou"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LE3D-d7JHOG3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "outputId": "b23fc65b-d350-4e01-c5af-c0370cdda9e6"
      },
      "source": [
        "column_names = [\"StartX\",\"StartY\",\"EndX\",\"EndY\",\"text\"]\n",
        "iou_threshold = 0.6\n",
        "\n",
        "precision_list = list()\n",
        "recall_list = list()\n",
        "wer_list = list()\n",
        "\n",
        "## Iterating over all the files in the ground truth directory\n",
        "\n",
        "for names in list_names:\n",
        "  \n",
        "  name_split = names.split(\"_\")\n",
        "  if len(name_split) == 3:\n",
        "    name = names.split(\"_\")\n",
        "    name_bbox = name[1] + \"_\" + name[2]\n",
        "  else:\n",
        "    name = names.split(\"_\")\n",
        "    name_bbox = name[1]\n",
        "  \n",
        "  actual_bbox = pd.read_csv(join('/content/Text_detection_and_extraction/text_detection/ground_truth',\"gt_\"+ name_bbox), sep=' ', names = column_names,index_col=None)\n",
        "  predicted_bbox_table = bbox_text_prediction[bbox_text_prediction[\"name\"] == name_bbox]\n",
        "  predicted_bbox_table = predicted_bbox_table[column_names]\n",
        "\n",
        "  if(len(predicted_bbox_table) == 0):\n",
        "    precision = 0.0\n",
        "    recall = 0.0\n",
        "    precision_list.extend([precision])\n",
        "    recall_list.extend([recall])\n",
        "\n",
        "  else:\n",
        "    actual_bbox_table_points = actual_bbox[[\"StartX\",\"StartY\",\"EndX\",\"EndY\"]]\n",
        "    actual_bbox_table_points[[\"StartX\",\"StartY\",\"EndX\",\"EndY\"]] = actual_bbox_table_points[[\"StartX\",\"StartY\",\"EndX\",\"EndY\"]].replace(\",\",\"\",regex = True)\n",
        "    actual_bbox_table_points[[\"StartX\",\"StartY\",\"EndX\",\"EndY\"]] = actual_bbox_table_points[[\"StartX\",\"StartY\",\"EndX\",\"EndY\"]].astype(float)\n",
        "\n",
        "    actual_bbox_list = (actual_bbox_table_points).values.tolist()\n",
        "    predicted_bbox_list = predicted_bbox_table[[\"StartX\",\"StartY\",\"EndX\",\"EndY\"]].values.tolist()\n",
        "\n",
        "    no_of_actual_boxes = len(actual_bbox_list)\n",
        "    no_of_pred_boxes = len(predicted_bbox_list)\n",
        "\n",
        "    iou_matrix = np.empty([no_of_pred_boxes,no_of_actual_boxes])\n",
        "\n",
        "    for i,pred_box in enumerate(predicted_bbox_list):\n",
        "      for j,actual_box in enumerate(actual_bbox_list):\n",
        "        iou_matrix[i,j] = bb_intersection_over_union(pred_box,actual_box)\n",
        "    \n",
        "    ## Extracting bounding boxes mased on IOU threshold\n",
        "    result = np.where(iou_matrix > iou_threshold)\n",
        "    pred_box_indices,actual_box_indices = result\n",
        "\n",
        "    ## Calculating the word error rate for the true positives\n",
        "\n",
        "    if(len(pred_box_indices)>0):\n",
        "      for j in range(0,len(pred_box_indices)):\n",
        "        pred_index = pred_box_indices[j]\n",
        "        actual_index = actual_box_indices[j]\n",
        "        predicted_bbox_text = re.sub('[^A-Za-z0-9]+', '', predicted_text[pred_index])\n",
        "        actual_bbox_text = re.sub('[^A-Za-z0-9]+', '', actual_text[actual_index])\n",
        "        error = wer(predicted_bbox_text, actual_bbox_text)\n",
        "        wer_list.extend([error])\n",
        "\n",
        "    ## Calculating true positives, false positives, false negatives, precision and recall\n",
        "    tp = len(np.unique(pred_box_indices))\n",
        "    fp = no_of_pred_boxes - tp\n",
        "    fn = no_of_actual_boxes - len(np.unique(actual_box_indices))\n",
        "    precision = tp/(tp+fp)\n",
        "    recall = tp/(tp+fn)\n",
        "    precision_list.extend([precision])\n",
        "    recall_list.extend([recall])\n",
        "\n",
        "print (\"Average precision for bbox detection:\", mean(precision_list))\n",
        "print (\"Average recall for bbox detection:\", mean(recall_list))\n",
        "print (\"Word error rate:\", (sum(wer_list)/len(wer_list)))"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py:3509: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self[k1] = value[k2]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Average precision for bbox detection: 0.884392395827702\n",
            "Average recall for bbox detection: 0.9094777282601958\n",
            "Word error rate: 0.6418685121107266\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}